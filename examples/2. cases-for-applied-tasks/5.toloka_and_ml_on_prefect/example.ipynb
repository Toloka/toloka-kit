{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd168c5d",
   "metadata": {},
   "source": [
    "This example illustrates how crowdsourcing using Toloka can be made easier and cheaper by integrating an ML model (which we refer to as an autohelper) into the usual pipeline. Furthermore, it shows how to run the whole project in the cloud using [Prefect](https://www.prefect.io/), which makes workflow orchestration much simpler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d00e1b",
   "metadata": {},
   "source": [
    "The main steps are:\n",
    "* setting up Prefect\n",
    "* getting predictions using ML\n",
    "* evaluating predictions' quality\n",
    "* sending tasks with prediction below a certain quality threshold to Toloka users\n",
    "* aggregating the results\n",
    "\n",
    "Such a process leads to better quality and helps spend less by reducing the number of manual tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4fac1b",
   "metadata": {},
   "source": [
    "## Setting up Prefect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5142eca",
   "metadata": {},
   "source": [
    "Prefect is a workflow management system, designed for modern infrastructure and powered by the open-source Prefect Core workflow engine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0286c77",
   "metadata": {},
   "source": [
    "Prefect offers many options for workflow management. We'll use its [cloud-based service](https://www.prefect.io/cloud/) for orchestration and run examples using local machine and local storage. What follows is a quick guide for setting it up (for more detailed information refer to [this material](https://docs.prefect.io/orchestration/getting-started/quick-start.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8179b38a",
   "metadata": {},
   "source": [
    "First, let's make sure prefect is installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c821700",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install prefect\n",
    "# !conda install -c conda-forge prefect\n",
    "# !pipenv install --pre prefect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4892dc48",
   "metadata": {},
   "source": [
    "To use Prefect Cloud we'll need to login to (or set up an account for) Prefect Cloud at https://cloud.prefect.io. Once it's done, let's set the backend to use Prefect Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df466104",
   "metadata": {},
   "outputs": [],
   "source": [
    "!prefect backend cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8dc6e3",
   "metadata": {},
   "source": [
    "Next, we'll need to authenticate with the backend - follow [these instructions](https://docs.prefect.io/orchestration/getting-started/set-up.html#authenticate-with-prefect-cloud) to do that, then enter your key in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9f8032",
   "metadata": {},
   "outputs": [],
   "source": [
    "YOUR_KEY = input()\n",
    "!prefect auth login --key $YOUR_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5b8ac2",
   "metadata": {},
   "source": [
    "All that remains is to create a project and start an agent that will run Prefect flows on the local machine.\n",
    "Prefect agent is responsible for starting and monitoring flow runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e789d22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = input()\n",
    "# PROJECT_NAME = 'Toloka test project 1'\n",
    "!prefect create project $PROJECT_NAME\n",
    "!prefect agent local start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8691fd95",
   "metadata": {},
   "source": [
    "Prefect uses an abstraction called [Executor](https://docs.prefect.io/api/latest/executors.html#executor) to run tasks, which is set to local by default, but also [natively supports](https://docs.prefect.io/orchestration/flow_config/executors.html#daskexecutor) dask. Other storage [types](https://docs.prefect.io/orchestration/flow_config/executors.html#daskexecutor) and agent [options](https://docs.prefect.io/orchestration/flow_config/executors.html#daskexecutor) are also supported, but we'll keep everything local for simplicity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6888dd",
   "metadata": {},
   "source": [
    "## Writing code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad96d78",
   "metadata": {},
   "source": [
    "For the project, we have a set of customer reviews, and we need to classify them as “Positive” or “Negative”. We ask performers to read a review and decide which category it belongs to.\n",
    "For more details refer to an official Toloka-kit [example](https://github.com/Toloka/toloka-kit/blob/main/examples/5.nlp/sentiment_analysis/sentiment_analysis.ipynb) which this project is based on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c1d051",
   "metadata": {},
   "source": [
    "### Call to action\n",
    "If you found some bugs or have a new feature idea, don't hesitate to [open a new issue on Github](https://github.com/Toloka/toloka-kit/issues/new/choose).\n",
    "Like our library and examples? Star [our repo on Github](https://github.com/Toloka/toloka-kit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dac8f66",
   "metadata": {},
   "source": [
    "Prepare environment and import all we'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "c4d20ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install toloka-kit==0.1.26\n",
    "!pip install crowd-kit==1.0.0\n",
    "\n",
    "import datetime\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "import getpass\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import toloka.client as toloka\n",
    "from toloka.client import Pool, Project, TolokaClient\n",
    "from toloka.client.analytics_request import CompletionPercentagePoolAnalytics\n",
    "from crowdkit.aggregation import DawidSkene\n",
    "\n",
    "import prefect\n",
    "from prefect import Flow, task\n",
    "from prefect.engine.results import LocalResult\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825a0ec9",
   "metadata": {},
   "source": [
    "Set up the steps for getting json configs for the project and the pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "16f2f13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "GITHUB_RAW = 'https://raw.githubusercontent.com'\n",
    "GITHUB_BASE_PATH = 'Toloka/toloka-kit/main/examples/9.toloka_and_ml_on_prefect/configs'\n",
    "\n",
    "\n",
    "def _load_json_from_github(filename: str):\n",
    "    response = requests.get(os.path.join(GITHUB_RAW, GITHUB_BASE_PATH, filename))\n",
    "    response.raise_for_status()\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952ceca7",
   "metadata": {},
   "source": [
    "Now we can start building the project.\n",
    "Prefect refers to each step as a [*task*](https://docs.prefect.io/core/about_prefect/thinking-prefectly.html#tasks). In a simple sense, a task is just a Python function representing a logically distinct stage of a process.\n",
    "This example is split into different tasks for project and pool creationg, data preparationa and finally task processing by autohelper and Toloka separately. Most tasks receive Toloka API token and env variable, which enables creating the Toloka client inside and solves possible difficulties involved in sharing such an object between different tasks.\n",
    "Some tasks also specify that `print()` statements inside should be sent to Prefect Cloud logs, which makes debugging easier: `@task(log_stdout=True)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713753f8",
   "metadata": {},
   "source": [
    "Let's create all the necessary blocks for our flow.\n",
    "First, create a project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1f9bed0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def create_project(token: str, env: str) -> str:\n",
    "    client = TolokaClient(token, env)\n",
    "    project = Project.structure(_load_json_from_github('project.json'))\n",
    "    project = client.create_project(project)\n",
    "    return project.id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f02e42",
   "metadata": {},
   "source": [
    "Create pool with a skill-check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "92698bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def create_skill(token: str, env: str, name='sentiment-analysis') -> str:\n",
    "    client = TolokaClient(token, env)\n",
    "    skill = next(client.get_skills(name=name), None) or client.create_skill(name=name)\n",
    "    return skill.id\n",
    "\n",
    "@task\n",
    "def create_pool(token: str, env: str, project_id: str, skill_id: str, reward: float) -> str:\n",
    "    client = TolokaClient(token, env)\n",
    "    pool = Pool.structure(_load_json_from_github('pool.json'))\n",
    "    pool.project_id = project_id\n",
    "    skill_filter = (toloka.filter.Skill(skill_id) == None) | (toloka.filter.Skill(skill_id) >= 90)\n",
    "    pool.set_filter(pool.filter & skill_filter)\n",
    "    pool.quality_control.add_action(\n",
    "        collector=toloka.collectors.GoldenSet(history_size=10),\n",
    "        conditions=[toloka.conditions.TotalAnswersCount > 4],\n",
    "        action=toloka.actions.SetSkillFromOutputField(skill_id=skill_id, from_field='correct_answers_rate')\n",
    "    )\n",
    "    pool.reward_per_assignment = reward\n",
    "    pool.will_expire=datetime.datetime.utcnow() + datetime.timedelta(days=7)\n",
    "    pool = client.create_pool(pool)\n",
    "    return pool.id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b72981",
   "metadata": {},
   "source": [
    "We will use [Grammar and Online Product Reviews](https://data.world/datafiniti/grammar-and-online-product-reviews) dataset under Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International license\n",
    "\n",
    "\n",
    "[![CC BY-NC-SA 4.0](https://img.shields.io/badge/License-CC%20BY--NC--SA%204.0-lightgrey.svg)](https://creativecommons.org/licenses/by-nc-sa/4.0/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c74391",
   "metadata": {},
   "source": [
    "Download the necessary data and separate it into golden and non-golden tasks.\n",
    "We'll use `cnt_tasks` of regular tasks and `cnt_golden` of golden tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "439e9e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task(nout=2, log_stdout=True)\n",
    "def prepare_dataset(\n",
    "    dataset_url: str,\n",
    "    cnt_tasks: int,\n",
    "    cnt_golden: int,\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    dataset = pd.read_csv(dataset_url)\n",
    "    print(f'Initial dataset size: {len(dataset)}')\n",
    "\n",
    "    dataset = dataset[['reviews.text', 'reviews.doRecommend']].dropna().reset_index(drop=True)\n",
    "    dataset = dataset.replace({'reviews.doRecommend': {True: 'pos', False: 'neg'}})\n",
    "\n",
    "    positive_tasks = dataset[dataset['reviews.doRecommend'] == 'pos']\n",
    "    negative_tasks = dataset[dataset['reviews.doRecommend'] == 'neg']\n",
    "    print(f'positive count: {len(positive_tasks)}. negative count: {len(negative_tasks)}')\n",
    "\n",
    "    slice_tasks = cnt_tasks // 2\n",
    "    slice_golden = slice_tasks + cnt_golden // 2\n",
    "    pos_task_dataset, pos_golden_dataset, _ = np.split(positive_tasks, [slice_tasks, slice_golden])\n",
    "    neg_task_dataset, neg_golden_dataset, _ = np.split(negative_tasks, [slice_tasks, slice_golden])\n",
    "\n",
    "    task_dataset = pd.concat([pos_task_dataset, neg_task_dataset])\n",
    "    golden_dataset = pd.concat([pos_golden_dataset, neg_golden_dataset])\n",
    "\n",
    "    return task_dataset, golden_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae1c08d",
   "metadata": {},
   "source": [
    "Create a function for getting the ML model and tokenizer, which will serve as an autohelper in our project. We'll use the readily-available models from [Hugging Face](https://huggingface.co/), namely [finetuned DistilBERT](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2a154b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_resources(model_name: str) -> Tuple[AutoModelForSequenceClassification, AutoTokenizer]:\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f240a6f",
   "metadata": {},
   "source": [
    "Set up a function to get autohelper predictions.\n",
    "We'll use confidence scores later on to decide whether to trust the autohelper answer or to send the task to Toloka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "29032ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch should be an array of reviews\n",
    "def _make_predictions(batch: List[str], model: AutoModelForSequenceClassification, tokenizer: AutoTokenizer):\n",
    "    batch = tokenizer(batch, padding=True, truncation=True, return_tensors='pt')\n",
    "    print('start apply...')\n",
    "    outputs = model(**batch)\n",
    "    print('apply done')\n",
    "    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1).detach().numpy()\n",
    "    # predictions are an array of pairs containing confidence scores for classes 0 and 1\n",
    "    # (in this order)\n",
    "    # therefore, (predictions[idx,1] > 0.5) is True if the model thinks\n",
    "    #   that element idx is in the class 'pos'\n",
    "    labels = np.vectorize(lambda flag: 'pos' if flag else 'neg')(predictions[:,1] > 0.5)\n",
    "    confidence = predictions.max(axis=1)\n",
    "    return labels, confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a3f515",
   "metadata": {},
   "source": [
    "Create a function to decide, which tasks got adequate answers from autohelper (`accepted_tasks`) and which should be sent to Toloka (`manual_tasks`).\n",
    "We assume that if a model performs below a certain confidence threshold, then the task should be given to Toloka users. For simplicity, the threshold is calculated as the 90th percentile of confidence scores on answers where the autohelper was wrong (this is a robust enough estimate for our case). To find it, we can use golden tasks for which we know the correct responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "50ca621d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task(nout=2, log_stdout=True)\n",
    "def apply(\n",
    "    model_name: str,\n",
    "    task_dataset: pd.DataFrame,\n",
    "    golden_dataset: pd.DataFrame,\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    model, tokenizer = _get_resources(model_name)\n",
    "    print(f'Model loaded: {model_name}')\n",
    "\n",
    "    # find the threshold using golden tasks:\n",
    "    golden_items = list(golden_dataset.iloc[:,0].values)\n",
    "    autohelper_golden_labels, golden_confidence = _make_predictions(golden_items, model, tokenizer)\n",
    "    # extract true answers\n",
    "    true_golden_labels = golden_dataset.iloc[:,1]\n",
    "    # find wrong answers\n",
    "    wrong_answers_mask = true_golden_labels != autohelper_golden_labels\n",
    "    # set threshold to 90th percentile of confidence scores when the model was wrong\n",
    "    # or if the model got all answers right, then set it to 0.95\n",
    "    if wrong_answers_mask.any():\n",
    "        threshold = np.percentile(golden_confidence[wrong_answers_mask], 90)\n",
    "    else:\n",
    "        threshold = 0.95\n",
    "\n",
    "    # find elements where we think the model is likely to predict the right answer\n",
    "    nongolden_items = list(task_dataset.iloc[:,0].values)\n",
    "    nongolden_labels, nongolden_confidence = _make_predictions(nongolden_items, model, tokenizer)\n",
    "    accepted_solutions_mask = nongolden_confidence > threshold\n",
    "\n",
    "    # make a dataframe from the answers which we accepted\n",
    "    accepted_tasks = pd.DataFrame({\n",
    "        'review': task_dataset[accepted_solutions_mask]['reviews.text'],\n",
    "        'sentiment': nongolden_labels[accepted_solutions_mask]\n",
    "    })\n",
    "    manual_tasks = task_dataset[~accepted_solutions_mask]\n",
    "\n",
    "    print(f'accepted_tasks count: {len(accepted_tasks)}')\n",
    "    print(f'manual_tasks count: {len(manual_tasks)}')\n",
    "\n",
    "    return accepted_tasks, manual_tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aff1b83",
   "metadata": {},
   "source": [
    "Send golden and manual non-golden tasks to toloka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8db1d70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def send_to_toloka(\n",
    "    token: str,\n",
    "    env: str,\n",
    "    pool_id: str,\n",
    "    golden_dataset: pd.DataFrame,\n",
    "    manual_tasks: pd.DataFrame,\n",
    ") -> None:\n",
    "    client = TolokaClient(token, env)\n",
    "\n",
    "    golden_tasks = [\n",
    "        toloka.Task(\n",
    "            pool_id=pool_id,\n",
    "            input_values={'review': row['reviews.text']},\n",
    "            known_solutions = [{'output_values': {'sentiment': row['reviews.doRecommend']}}],\n",
    "            infinite_overlap=True,\n",
    "        )\n",
    "        for _, row in golden_dataset.iterrows()\n",
    "    ]\n",
    "\n",
    "    tasks = [\n",
    "        toloka.Task(pool_id=pool_id, input_values={'review': review})\n",
    "        for review in manual_tasks['reviews.text']\n",
    "    ]\n",
    "\n",
    "    client.create_tasks(golden_tasks + tasks, allow_defaults=True, open_pool=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783ed081",
   "metadata": {},
   "source": [
    "Create a process to await pool's completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2074e39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task(log_stdout=True)\n",
    "def wait_pool_for_close(token: str, env: str, pool_id: str) -> None:\n",
    "    client = TolokaClient(token, env)\n",
    "\n",
    "    while True:\n",
    "        pool = client.get_pool(pool_id)\n",
    "        if pool.is_closed():\n",
    "            print(f'Pool {pool_id} is closed.')\n",
    "            return\n",
    "        op = client.get_analytics([CompletionPercentagePoolAnalytics(subject_id=pool_id)])\n",
    "        percentage = client.wait_operation(op).details['value'][0]['result']['value']\n",
    "        print(f'   {datetime.datetime.now().strftime(\"%H:%M:%S\")}\\t'\n",
    "              f'Pool {pool_id} - {percentage}%')\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75501352",
   "metadata": {},
   "source": [
    "Create a task for processing Toloka responses and combining them with autohelper's answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92aa5553",
   "metadata": {},
   "source": [
    "We'll run aggregation using the Dawid-Skene model.\n",
    "\n",
    "We use this aggregation model because our questions are of the same difficulty, and we don't have many control tasks.\n",
    "\n",
    "Read more about the Dawid-Skene model in the Requester’s Guide or get at an overview of different aggregation models in our Knowledge Base.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1753d094",
   "metadata": {},
   "source": [
    "In order to save the data, we'll use Prefect's [output persistance option](https://docs.prefect.io/core/concepts/persistence.html#persisting-output), setting task's `checkpoint` flag to `True` and specifying the location where the pickled version of our information will be stored using Prefect's `LocalResult` (`dir` is the directory for the result, `location` is the file's name, so this file's relative path will be `./prefect_results/sentiments`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "26ba115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task(\n",
    "    log_stdout=True,\n",
    "    checkpoint=True,\n",
    "    result=LocalResult(dir=\"./prefect_results\", location='sentiments')\n",
    ")\n",
    "def collect_results(\n",
    "    token: str,\n",
    "    env: str,\n",
    "    pool_id: str,\n",
    "    autohelper_results: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    client = TolokaClient(token, env)\n",
    "\n",
    "    toloka_answers_df = client.get_assignments_df(pool_id)\n",
    "    # Drop golden tasks\n",
    "    toloka_answers_df = toloka_answers_df[toloka_answers_df['GOLDEN:sentiment'].isna()]\n",
    "    # Prepare DataFrame for aggregation\n",
    "    toloka_answers_df = toloka_answers_df.rename(columns={\n",
    "        'INPUT:review': 'task',\n",
    "        'OUTPUT:sentiment': 'label',\n",
    "        'ASSIGNMENT:worker_id': 'worker'\n",
    "    })\n",
    "\n",
    "    print(f'Toloka answers count: {len(answers_df)}')\n",
    "\n",
    "    toloka_predicted_answers = DawidSkene(n_iter=20).fit_predict(toloka_answers_df)\n",
    "    toloka_results = pd.DataFrame({\n",
    "        'review': toloka_predicted_answers.index,\n",
    "        'sentiment': toloka_predicted_answers.values\n",
    "    })\n",
    "\n",
    "    answers = pd.concat([autohelper_results, toloka_results])\n",
    "\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bbec17",
   "metadata": {},
   "source": [
    "Now we can finally set up our flow. We'll use Prefect's [Parameters](https://docs.prefect.io/core/concepts/parameters.html) to securely send Toloka API token to the flow and to choose the environment (`SANDBOX` or `PRODUCTION`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b16473a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with Flow('ML assisted pipeline example') as flow:\n",
    "    # Toloka API token\n",
    "    token = prefect.Parameter('token')\n",
    "    # project environment\n",
    "    env = prefect.Parameter('env')\n",
    "\n",
    "    DATASET_URL = 'https://tlk.s3.yandex.net/ext_dataset/datafiniti_grammar_and_online_product_reviews.csv'\n",
    "    model_name = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
    "\n",
    "    project_id = create_project(token, env)\n",
    "    skill_id = create_skill(token, env)\n",
    "    pool_id = create_pool(token, env, project_id, skill_id, reward=0.03)\n",
    "\n",
    "    task_dataset, golden_dataset = prepare_dataset(DATASET_URL, cnt_tasks=200, cnt_golden=20)\n",
    "    accepted_tasks, manual_tasks = apply(model_name, task_dataset, golden_dataset)\n",
    "\n",
    "    sent = send_to_toloka(token, env, pool_id, golden_dataset, manual_tasks)\n",
    "    pooling = wait_pool_for_close(token, env, pool_id).set_upstream(sent)\n",
    "\n",
    "    collect_results(token, env, pool_id, accepted_tasks).set_upstream(pooling)\n",
    "\n",
    "# register the flow with the project we've created in the beginning\n",
    "# flow.register(project_name=PROJECT_NAME)\n",
    "flow.register(project_name=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cc48ef",
   "metadata": {},
   "source": [
    "Go to the link in the last cell's output, leading to the Prefect Cloud UI\n",
    "<img src=\"https://raw.githubusercontent.com/Toloka/toloka-kit/main/examples/9.toloka_and_ml_on_prefect/images/tabs.png\" alt=\"Tabs\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5b703e",
   "metadata": {},
   "source": [
    "Click on the *SETTINGS* tab and turn *Heartbeat* off. Tasks send *heartbeats* at regular intervals, if they're maling progress, and it's Prefect's way of protecting against zombie tasks (more info [here](https://docs.prefect.io/orchestration/concepts/services.html#zombie-killer)). But in our case, Toloka  users may be slow and not have enough time to submit an answer before Prefect starts thinking the *pooling* task is a zombie\n",
    "<img src=\"https://raw.githubusercontent.com/Toloka/toloka-kit/main/examples/9.toloka_and_ml_on_prefect/images/heartbeat.png\" alt=\"Heartbeat\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5817b418",
   "metadata": {},
   "source": [
    "Next, navigate to the *RUN* tab, input the *env* and *token* and click on run in the bottom of the page\n",
    "<img src=\"https://raw.githubusercontent.com/Toloka/toloka-kit/main/examples/9.toloka_and_ml_on_prefect/images/parameters.png\" alt=\"Parameters\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef3a1e8",
   "metadata": {},
   "source": [
    "You can also use the Cloud UI to inspect the flow's progress, see its structure (the *SCHEMATIC* tab), view the logs (choose the necessary *run* in the *RUNS* tab and select the *LOGS* tab) and many other things."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672789ee",
   "metadata": {},
   "source": [
    "## Viewing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de20e044",
   "metadata": {},
   "source": [
    "Let's unpickle the data we've saved and view it (by default, Prefect uses `cloudpickle` for data serialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c290a23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle\n",
    "\n",
    "FILEPATH = './prefect_results/sentiments'\n",
    "with open(FILEPATH, 'rb') as file:\n",
    "    results = cloudpickle.loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "476cb69e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Great product! Exactly what it says works very...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>This cream did not do much for my face or thro...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Got as a surprise for my husband there is noth...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>I've been using this product for years and it ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I bought this to try to spice things up, but I...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bought this to enhance our time a bit, did abs...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Exceptional product, this is smooth, not slimy...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>You will LOVE this lotion. I smile every time ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I bought this because it had better reviews th...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>I am so disappointed! I have used this product...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review sentiment\n",
       "24  Great product! Exactly what it says works very...       pos\n",
       "49  This cream did not do much for my face or thro...       neg\n",
       "6   Got as a surprise for my husband there is noth...       neg\n",
       "53  I've been using this product for years and it ...       neg\n",
       "13  I bought this to try to spice things up, but I...       neg\n",
       "9   Bought this to enhance our time a bit, did abs...       pos\n",
       "22  Exceptional product, this is smooth, not slimy...       pos\n",
       "27  You will LOVE this lotion. I smile every time ...       pos\n",
       "14  I bought this because it had better reviews th...       neg\n",
       "52  I am so disappointed! I have used this product...       neg"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sample(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
